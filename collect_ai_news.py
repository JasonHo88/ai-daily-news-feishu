#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIèµ„è®¯æ”¶é›†è„šæœ¬ï¼ˆå¤šæº RSS æ——èˆ°ç‰ˆï¼‰
èšåˆ 36Kr, ITä¹‹å®¶, å°‘æ•°æ´¾, æå®¢å…¬å›­, è™å—…, AI News, TechCrunch
"""

import os
import sys
import re
from datetime import datetime
from typing import Dict, List
import requests
import feedparser
from deep_translator import GoogleTranslator

# --- ç¯å¢ƒé…ç½® ---
# é£ä¹¦ Webhook åœ°å€ä» GitHub Secrets ä¸­è¯»å–
FEISHU_WEBHOOK_URL = os.getenv('FEISHU_WEBHOOK_URL', '')
TODAY = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

# åˆå§‹åŒ–ç¿»è¯‘å™¨ (è‹±ç¿»ä¸­)
translator = GoogleTranslator(source='auto', target='zh-CN')

class NewsEngine:
    def __init__(self):
        self.seen_titles = set()

    def translate(self, text: str) -> str:
        """åœ¨çº¿ç¿»è¯‘æ ‡é¢˜"""
        if not text: return ""
        try:
            return translator.translate(text)
        except:
            return text

    def is_dup(self, title: str) -> bool:
        """ç®€æ˜“æŒ‡çº¹å»é‡é€»è¾‘"""
        clean = re.sub(r'[^\w\u4e00-\u9fa5]', '', title.lower())[:15]
        if not clean or clean in self.seen_titles:
            return True
        self.seen_titles.add(clean)
        return False

def fetch_domestic_rss(engine: NewsEngine) -> List[Dict]:
    """èšåˆå›½å†…ç§‘æŠ€åª’ä½“ RSS æº"""
    sources = [
        {"name": "36æ°ª", "url": "https://36kr.com/feed-article"},
        {"name": "ITä¹‹å®¶", "url": "https://www.ithome.com/rss/"},
        {"name": "å°‘æ•°æ´¾", "url": "https://sspai.com/feed"},
        {"name": "æå®¢å…¬å›­", "url": "http://www.geekpark.net/rss"},
        {"name": "è™å—…", "url": "https://www.huxiu.com/rss/0.xml"}
    ]
    results = []
    for src in sources:
        try:
            print(f"ğŸ‡¨ğŸ‡³ åŒæ­¥ä¸­: {src['name']}")
            feed = feedparser.parse(src['url'])
            count = 0
            for entry in feed.entries:
                if count >= 3: break # æ¯ä¸ªæºç²¾é€‰3æ¡
                if not engine.is_dup(entry.title):
                    results.append({"title": entry.title, "source": src['name'], "link": entry.link})
                    count += 1
        except Exception as e:
            print(f"âš ï¸ {src['name']} æš‚æ—¶æ— æ³•è¿æ¥: {e}")
    return results

def fetch_overseas_rss(engine: NewsEngine) -> List[Dict]:
    """æŠ“å–æµ·å¤–æºå¹¶è‡ªåŠ¨ç¿»è¯‘"""
    sources = [
        {"name": "AI News", "url": "https://www.artificialintelligence-news.com/feed/"},
        {"name": "TechCrunch", "url": "https://techcrunch.com/category/artificial-intelligence/feed/"}
    ]
    results = []
    for src in sources:
        try:
            print(f"ğŸŒ ç¿»è¯‘ä¸­: {src['name']}")
            feed = feedparser.parse(src['url'])
            for entry in feed.entries[:4]:
                if not engine.is_dup(entry.title):
                    results.append({
                        "title": engine.translate(entry.title),
                        "source": src['name'],
                        "link": entry.link
                    })
        except:
            pass
    return results

def main():
    engine = NewsEngine()
    print("ğŸš€ æ­£åœ¨æ”¶é›†å…¨çƒ AI æƒ…æŠ¥...")
    
    domestic = fetch_domestic_rss(engine)
    overseas = fetch_overseas_rss(engine)
    
    if not domestic and not overseas:
        print("âŒ æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆèµ„è®¯")
        return

    # æ„é€ é£ä¹¦ Markdown å†…å®¹
    report = f"# ğŸ¤– å…¨çƒ AI ç§‘æŠ€æ—¥æŠ¥ - {TODAY}\n\n"
    
    report += "## ğŸŒ æµ·å¤–å‰æ²¿ (æ™ºèƒ½ç¿»è¯‘)\n\n"
    for i, n in enumerate(overseas[:8], 1):
        report += f"**{i}. {n['title']}**\n- æ¥æº: {n['source']} | [åŸæ–‡é“¾æ¥]({n['link']})\n\n"
    
    report += "## ğŸ‡¨ğŸ‡³ å›½å†…åŠ¨æ€ (å¤šæºèšåˆ)\n\n"
    for i, n in enumerate(domestic[:10], 1):
        report += f"**{i}. {n['title']}**\n- æ¥æº: {n['source']} | [é˜…è¯»å…¨æ–‡]({n['link']})\n\n"
    
    report += f"---\n*æƒ…æŠ¥è¦†ç›–: 36Kr, ITä¹‹å®¶, å°‘æ•°æ´¾, æå®¢å…¬å›­, è™å—…, AI News, TechCrunch*"

    # å‘é€è‡³é£ä¹¦
    if FEISHU_WEBHOOK_URL:
        payload = {
            "msg_type": "interactive",
            "card": {
                "header": {"title": {"tag": "plain_text", "content": f"ğŸ¤– AIç§‘æŠ€æƒ…æŠ¥ - {TODAY}"}, "template": "purple"},
                "elements": [{"tag": "markdown", "content": report}]
            }
        }
        res = requests.post(FEISHU_WEBHOOK_URL, json=payload, timeout=20)
        if res.status_code == 200:
            print("âœ… æ—¥æŠ¥æ¨é€å®Œæˆï¼")
        else:
            print(f"âŒ é£ä¹¦æ¥å£æŠ¥é”™: {res.text}")
    else:
        print("âš ï¸ æœªé…ç½® Webhookï¼Œä»…æ‰“å°é¢„è§ˆ:\n", report)

if __name__ == "__main__":
    main()
